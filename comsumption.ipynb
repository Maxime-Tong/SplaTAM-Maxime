{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ccf5d3c",
   "metadata": {},
   "source": [
    "## Number of energy consumption\n",
    "For each gaussian:\n",
    "- `preprocessCUDA`: 151 MACs\n",
    "For each elem:\n",
    "- `radix sort`: 24 MACs\n",
    "For each pixel:\n",
    "- `render`: 3 + r * (1 + 256 * 14) + 2 * 3 = 9 + r * 3585\n",
    "## Basic Information\n",
    "width: 1200\n",
    "height: 680\n",
    "\n",
    "Mapping step 5:\n",
    "tile.x, tile.y = 75, 43\n",
    "num_sort = 23463167\n",
    "P = 867364\n",
    "mean rounds: 2.9\n",
    "visible gaussians = 833384\n",
    "\n",
    "## Metrics\n",
    "Original for frames 30:\n",
    "\n",
    "- Final Average ATE RMSE: 0.04 cm\n",
    "- Average PSNR: 40.63\n",
    "- Average Depth RMSE: 0.18 cm\n",
    "- Average Depth L1: 0.18 cm\n",
    "- Average MS-SSIM: 0.996\n",
    "- Average LPIPS: 0.024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3f1f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_x, tile_y = 75, 43\n",
    "block_size = 256\n",
    "e = 0.5 # pj/MAC\n",
    "\n",
    "# Mapping step 5:\n",
    "sort_size = 23463167\n",
    "P = 867364\n",
    "visible_gaussians = 833384\n",
    "mean_rounds = 2.9\n",
    "\n",
    "preprocess = 151 * visible_gaussians\n",
    "radix_sort = 24 * sort_size\n",
    "render =  (3 + mean_rounds * (1 + block_size * 14) + 2 * 3) * block_size * tile_x * tile_y\n",
    "\n",
    "print(f\"Preprocess: {preprocess * e / 1e6:.2f} muj\")\n",
    "print(f\"Radix sort: {radix_sort * e / 1e6:.2f} muj\")\n",
    "print(f\"Render: {render * e / 1e6:.2f} muj\")\n",
    "print(f\"Total: {(preprocess + radix_sort + render) * e / 1e6:.2f} muj\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f76570",
   "metadata": {},
   "source": [
    "# Test image descriptor match algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9febd5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_matches(img1, img2, kp1, kp2, matches, title=\"Feature Matches\"):\n",
    "    \"\"\"\n",
    "    Visualize feature matching results\n",
    "    :param img1: first input image\n",
    "    :param img2: second input image\n",
    "    :param kp1: keypoints from first image\n",
    "    :param kp2: keypoints from second image\n",
    "    :param matches: list of matched keypoints\n",
    "    :param title: title for the plot\n",
    "    \"\"\"\n",
    "    # Draw matches between images\n",
    "    img_matches = cv2.drawMatches(img1, kp1, img2, kp2, matches, None, \n",
    "                                 flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    \n",
    "    # Convert to RGB format for matplotlib display\n",
    "    img_matches_rgb = cv2.cvtColor(img_matches, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Display the image\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.imshow(img_matches_rgb)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def match_features(img1, img2, method='ORB', ratio_thresh=0.7):\n",
    "    \"\"\"\n",
    "    Main feature matching function\n",
    "    :param img1: first input image\n",
    "    :param img2: second input image\n",
    "    :param method: feature matching method to use (SIFT, ORB, AKAZE, BRISK)\n",
    "    :param ratio_thresh: ratio threshold for nearest neighbor matching\n",
    "    :return: tuple of (keypoints1, keypoints2, good_matches)\n",
    "    \"\"\"\n",
    "    # Convert images to grayscale\n",
    "    gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Initialize feature detector and descriptor based on selected method\n",
    "    if method == 'SIFT':\n",
    "        detector = cv2.SIFT_create()\n",
    "        norm_type = cv2.NORM_L2  # SIFT uses L2 norm for descriptor matching\n",
    "    elif method == 'ORB':\n",
    "        detector = cv2.ORB_create()\n",
    "        norm_type = cv2.NORM_HAMMING  # ORB uses Hamming distance\n",
    "    elif method == 'AKAZE':\n",
    "        detector = cv2.AKAZE_create()\n",
    "        norm_type = cv2.NORM_HAMMING\n",
    "    elif method == 'BRISK':\n",
    "        detector = cv2.BRISK_create()\n",
    "        norm_type = cv2.NORM_HAMMING\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported method. Choose from: SIFT, SURF, ORB, AKAZE, BRISK\")\n",
    "    \n",
    "    # Detect keypoints and compute descriptors\n",
    "    kp1, des1 = detector.detectAndCompute(gray1, None)\n",
    "    kp2, des2 = detector.detectAndCompute(gray2, None)\n",
    "    \n",
    "    # Use brute-force matcher to find matches\n",
    "    matcher = cv2.BFMatcher(norm_type)\n",
    "    matches = matcher.knnMatch(des1, des2, k=2)  # Get top 2 matches for each descriptor\n",
    "    \n",
    "    # Apply ratio test to filter good matches\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < ratio_thresh * n.distance:\n",
    "            good_matches.append(m)\n",
    "    \n",
    "    return kp1, kp2, good_matches\n",
    "\n",
    "# Read input images\n",
    "base = \"/home/xthuang/code/slam/copy/SplaTAM-Maxime/data/Replica/room0/results\"\n",
    "img1 = cv2.imread(base + '/frame000042.jpg')  # Replace with your image path\n",
    "img2 = cv2.imread(base + '/frame000043.jpg')  # Replace with your image path\n",
    "\n",
    "if img1 is None or img2 is None:\n",
    "    raise ValueError(\"Failed to load images. Please check file paths\")\n",
    "\n",
    "# Available feature matching methods to test\n",
    "methods = ['ORB', 'SIFT', 'SURF', 'AKAZE', 'BRISK']\n",
    "\n",
    "for method in methods:\n",
    "    try:\n",
    "        print(f\"Performing feature matching using {method}...\")\n",
    "        kp1, kp2, good_matches = match_features(img1, img2, method=method)\n",
    "        print(f\"Found {len(good_matches)} good matches\")\n",
    "        \n",
    "        # Visualize the matching results\n",
    "        visualize_matches(img1, img2, kp1, kp2, good_matches, \n",
    "                        title=f\"Feature Matching using {method} (Matches: {len(good_matches)})\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {method}: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "splatam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
